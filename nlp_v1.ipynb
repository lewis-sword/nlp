{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f274994",
   "metadata": {},
   "source": [
    "# Natural language processing: tokenisation, vectorisation and word embeddings #\n",
    "Notebook looking at tokenisation and word embeddings. Further explanation of word2vec provided at https://arxiv.org/pdf/1411.2738.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667a0450-6e25-4232-86ad-a4cb4afb28ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1/. Tokenisation and vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e903568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe2b0d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#!pip install -U gensim\n",
    "#nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c9278",
   "metadata": {},
   "source": [
    "Language in machine learning models is usually broken down/tokenised where each word, sentence of phrase is classed as a token. W can manually read in a book and clean the text so that we only retain certain words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd3100d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['**the', 'project', 'gutenberg', 'etext', 'of', 'moby', 'dick,', 'by', 'herman', 'melville**', '#3', 'in', 'our', 'series', 'by', 'herman', 'melville', 'this', 'project', 'gutenberg', 'version', 'of', 'moby', 'dick', 'is', 'based', 'on', 'a', 'combination', 'of', 'the', 'etext', 'from', 'the', 'eris', 'project', 'at', 'virginia', 'tech', 'and', 'another', 'from', 'project', \"gutenberg's\", 'archives,', 'as', 'compared', 'to', 'a', 'public-domain', 'hard', 'copy.', 'copyright', 'laws', 'are', 'changing', 'all', 'over', 'the', 'world,', 'be', 'sure', 'to', 'check', 'the', 'copyright', 'laws', 'for', 'your', 'country', 'before', 'posting', 'these', 'files!!', 'please', 'take', 'a', 'look', 'at', 'the', 'important', 'information', 'in', 'this', 'header.', 'we', 'encourage', 'you', 'to', 'keep', 'this', 'file', 'on', 'your', 'own', 'disk,', 'keeping', 'an', 'electronic', 'path']\n"
     ]
    }
   ],
   "source": [
    "filename = 'moby_dick.txt'\n",
    "file = open(filename, 'rt')\n",
    "text = file.read()\n",
    "file.close()\n",
    "# split into words by white space\n",
    "words = text.split()\n",
    "# convert to lowercase\n",
    "words = [word.lower() for word in words]\n",
    "# printing the first 100 words\n",
    "print(words[0:100]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf6affd",
   "metadata": {},
   "source": [
    "However, we can also use library nltk which has a tokenize program which can handle .txt files and more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e77c6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['*', '*', 'The', 'Project', 'Gutenberg', 'Etext', 'of', 'Moby', 'Dick', ',', 'by', 'Herman', 'Melville', '*', '*', '#', '3', 'in', 'our', 'series', 'by', 'Herman', 'Melville', 'This', 'Project', 'Gutenberg', 'version', 'of', 'Moby', 'Dick', 'is', 'based', 'on', 'a', 'combination', 'of', 'the', 'etext', 'from', 'the', 'ERIS', 'project', 'at', 'Virginia', 'Tech', 'and', 'another', 'from', 'Project', 'Gutenberg', \"'s\", 'archives', ',', 'as', 'compared', 'to', 'a', 'public-domain', 'hard', 'copy', '.', 'Copyright', 'laws', 'are', 'changing', 'all', 'over', 'the', 'world', ',', 'be', 'sure', 'to', 'check', 'the', 'copyright', 'laws', 'for', 'your', 'country', 'before', 'posting', 'these', 'files', '!', '!', 'Please', 'take', 'a', 'look', 'at', 'the', 'important', 'information', 'in', 'this', 'header', '.', 'We', 'encourage']\n"
     ]
    }
   ],
   "source": [
    "# split into words\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "#performs slightly finer-grain tokenising\n",
    "print(tokens[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf92b094-4ab0-476d-9330-25b488400a60",
   "metadata": {},
   "source": [
    "Same idea can be repeated for sentences..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1ea8b77-0f97-490b-92f3-28b4a012fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9942\n",
      "['From\\nthence it is the God of breezes fair or foul is first invoked for\\nfavourable winds.', \"Yes, the world's a ship on its passage out, and not\\na voyage complete; and the pulpit is its prow.\"]\n"
     ]
    }
   ],
   "source": [
    "sentences = nltk.sent_tokenize(text) \n",
    "print(len(sentences))\n",
    "print(sentences[1000:1002])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f408aa9d-b3d2-4cb0-8c07-97a722b3a664",
   "metadata": {},
   "source": [
    "Say we have a corpus of data like a book. The book contains words, which form phrases/sentences. \n",
    "- We can perform some primary statistical measures of the words in a given corpus using basic counts or term frequency-inverse document frequency (tf-idf). This can give insight into the importance of the words.\n",
    "- Each unqiue word in the book, is part of a vocabulary `vocab`. We can represent each of these words as a vector of length `len(vocab)`, based on its counts/tf-idf values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbe36ad-e679-4fc3-980f-8fc876c19ad5",
   "metadata": {},
   "source": [
    "**Counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d77c999-9180-40c2-8ab0-ededa0efbdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 1 1 0 1 1 2]\n",
      " [0 1 0 1 0 0 1 1 0 2]\n",
      " [0 0 1 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# list of text documents. We call the sentences/phrases documents here, the collection of which froms the text.\n",
    "text = [\"The quick brown fox jumped over the lazy dog.\",\n",
    " \"The dog is over the moon\",\n",
    " \"The fox\"]\n",
    "c_vectorizer = CountVectorizer()\n",
    "c_vec_fit=c_vectorizer.fit(text)\n",
    "matrix_c_vec = c_vectorizer.transform(text)\n",
    "#Below we print out a row (documents) vs. column (possible words) matrix, where each cell corresponds to the word count in the document.\n",
    "print(matrix_c_vec.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6ecceb-ef98-4293-b6e0-2ea96760a6a5",
   "metadata": {},
   "source": [
    "The output therefore provides a simple matrix of row vectors: the rows defined by the documents in the text, and these row vector elements by the counts.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c359e54-c4de-4e7a-9e3d-1844cbe7b4d0",
   "metadata": {},
   "source": [
    "**tf-idf**\n",
    "\n",
    "Terms \"tf\" and \"idf\"  (https://en.wikipedia.org/wiki/Tf%E2%80%93idf) can have different definitions and sklearn's are described below.\n",
    "\n",
    "- tf(doc, term) stands for term frequency. In sklearn this simply means the number of times the \"term\" appears in the selected \"doc\". E.g. in doc = text[1], term=\"the\" appears twice, hence tf(text[1],\"the\") =2.\n",
    "- idf stands for inverse document frequency. To calculate each terms idf value using formula `np.log((N+1)/(df+1))+1` where $N$ is number of documents in the corpus(corpus being `text`) and $df$ is the number of documents in the corpus that contain the specific term. Note this value is independent of specific words appearing in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2532d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 9, 'quick': 8, 'brown': 0, 'fox': 2, 'jumped': 4, 'over': 7, 'lazy': 5, 'dog': 1, 'is': 3, 'moon': 6}\n",
      "[1.69314718 1.28768207 1.28768207 1.69314718 1.69314718 1.69314718\n",
      " 1.69314718 1.28768207 1.69314718 1.        ]\n",
      "  (0, 9)\t0.5536419417527538\n",
      "  (0, 7)\t0.3564574014762071\n",
      "  (0, 6)\t0.46869864635920433\n",
      "  (0, 3)\t0.46869864635920433\n",
      "  (0, 1)\t0.3564574014762071\n",
      "(1, 10)\n",
      "[[0.         0.3564574  0.         0.46869865 0.         0.\n",
      "  0.46869865 0.3564574  0.         0.55364194]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# list of text documents\n",
    "text = [\"The quick brown fox jumped over the lazy dog.\",\n",
    " \"The dog is over the moon\",\n",
    " \"The fox\"]\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)\n",
    "# # encode document\n",
    "vector_test = vectorizer.transform([text[1]])\n",
    "print(vector_test)\n",
    "# summarize encoded vector\n",
    "print(vector_test.shape)\n",
    "print(vector_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd108bb1-8713-49a1-bf98-1f2020460270",
   "metadata": {},
   "source": [
    "- In the text saved above there is 10 unique words, and upon applying the tf-idf vecotrizer, each vector component is assigned to a word/token. This is accessed through attribute `vocabulary_`. \n",
    "\n",
    "- The `idf_` attribute returns inverse document frequency values per word.\n",
    "\n",
    "- Note in `text[1]`, which is what we transform in `vector_test`, there are 2 \"the\", 1 \"dog\", 2 \"fox\" and 1 everything else. So naturally, there are only three unique numerical weight values. Why do they take these values? https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a561b25-c5b1-4cd5-a5ed-91d3090f83a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6931471805599454, 1.2876820724517808, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# N = Number of documents in corpus/text. idf_list appends all the different idf values. The number of unique values corresponds to the number of \n",
    "# unique word counts. We have counts 1 (e.g. \"quick\"), 2 (e.g. \"dog\") and 3 (\"the\")\n",
    "N=3\n",
    "idf_list=[]\n",
    "for df in [1,2,3]:\n",
    "    idf=np.log((N+1)/(df+1))+1\n",
    "    idf_list.append(idf)\n",
    "print(idf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d98536-df6b-4f3b-88ba-f2aca88b806e",
   "metadata": {},
   "source": [
    "To calculate the component of the transformed/encoded vector for each document in the text, we take each words' idf and multiply it by the words' tf (that is term frequency and here it is simply the number of times the term appears in the chosen document). This result we set as the \"term\" component of the vector. Importantly the end vector is normalised  as $||v|| = \\sqrt{v \\cdot v} = 1$. As an explicit example, take document `text[1]` and let us calculate its transformed vector representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf598e70-1f8e-4ba7-9bff-d49dc0e05b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5536419417527538\n",
      "0.3564574014762071\n",
      "0.46869864635920433\n"
     ]
    }
   ],
   "source": [
    "norm_text1 = np.sqrt((2*idf_list[2])**2 + (1*idf_list[1])**2 +(1*idf_list[1])**2 + (1*idf_list[0])**2 + (1*idf_list[0])**2 )\n",
    "#print(norm_text1)\n",
    "print(idf_list[2]*2/norm_text1)# Corresponds to \"the\". Note the factor of 2, since tf(text[1],\"the\") = 2 i.e. \"the\" appears twice in document text[1]\n",
    "print(idf_list[1]*1/norm_text1)# Corresponds to \"dog\" and \"over\"\n",
    "print(idf_list[0]*1/norm_text1)# Corresponds to \"is\" and \"moon\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9315da6a-aa6a-4c9f-af98-333966241746",
   "metadata": {},
   "source": [
    "These are the entries that appear in the corresponding vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb35f1b-beeb-43be-941a-c26c8648b73e",
   "metadata": {},
   "source": [
    "Running the transform on the whole text and formatting into an array, the arrays rows are the document, while its columns are all the possible words from the corpus/text. The cell values are the tf-idf values as we have seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "577302b1-a74a-4e18-8aae-5b6dd4815594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t0.44235918641789485\n",
      "  (0, 8)\t0.374489604639125\n",
      "  (0, 7)\t0.28480899696733925\n",
      "  (0, 5)\t0.374489604639125\n",
      "  (0, 4)\t0.374489604639125\n",
      "  (0, 2)\t0.28480899696733925\n",
      "  (0, 1)\t0.28480899696733925\n",
      "  (0, 0)\t0.374489604639125\n",
      "  (1, 9)\t0.5536419417527538\n",
      "  (1, 7)\t0.3564574014762071\n",
      "  (1, 6)\t0.46869864635920433\n",
      "  (1, 3)\t0.46869864635920433\n",
      "  (1, 1)\t0.3564574014762071\n",
      "  (2, 9)\t0.6133555370249717\n",
      "  (2, 2)\t0.7898069290660905\n",
      "(3, 10)\n",
      "[[0.3744896  0.284809   0.284809   0.         0.3744896  0.3744896\n",
      "  0.         0.284809   0.3744896  0.44235919]\n",
      " [0.         0.3564574  0.         0.46869865 0.         0.\n",
      "  0.46869865 0.3564574  0.         0.55364194]\n",
      " [0.         0.         0.78980693 0.         0.         0.\n",
      "  0.         0.         0.         0.61335554]]\n"
     ]
    }
   ],
   "source": [
    "vector = vectorizer.transform(text)\n",
    "print(vector)\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830a319-5a33-45d6-b7c6-503fde722fdb",
   "metadata": {},
   "source": [
    "Like the standard counts, tf-idf therefore produces a matrix of document row vectors, each vector component corresponding to the tf-idf value of a given word. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365ebbea-a2a5-4838-a1ad-3875269ca26a",
   "metadata": {},
   "source": [
    "Both counts and tf-idf provide a way of transforming text data to numerical data such that it can be passed into NLP algorithms. The downside of these input values is that they do not carry with them semantic information (at least directly). For that reason, we look to word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f1aaef-6c6d-4113-ac30-38e1a5683f48",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2/. Word embeddings ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3280f0-661b-48cd-ac61-f7bae19d47aa",
   "metadata": {},
   "source": [
    "Word embedding means representing words appearing in a corpus, as a real valued vector in an alternative dimensional vector space. The process is able to capture inter-word semantics. The vocabulary vectors can then be processed using machine learning techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc153a69-628f-4de9-9c6a-972565704335",
   "metadata": {},
   "source": [
    "The method involves iteration over a corpus of text to learn the association between the words. It relies on a hypothesis that the neighboring words in a text have semantic similarities with each other. It assists in mapping semantically similar words to geometrically close embedding vectors and uses the cosine metric to measure semantic similarity. Cosine similarity is equal to Cos(angle) where the angle is measured between the vector representation of two words/documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368dd03d-a996-4db4-bdf8-8ddbbb45411f",
   "metadata": {},
   "source": [
    "**word2vec**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4505e3-8af0-4ac3-a5f7-5d8434760129",
   "metadata": {},
   "source": [
    "Word2vec is a two-layer neural net that processes text by “vectorizing” words. Its input is a text corpus and its output is a set of vectors: feature vectors that represent words in that corpus. While Word2vec is not a deep neural network, it turns text into a numerical form that deep neural networks can understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d15fe3-b55d-4c69-ba7d-3f40d97e0a98",
   "metadata": {},
   "source": [
    "There are two word2vec architectures: continuous bag of words (CBOW) and Skip-gram. Using context words to predict a target word is the CBOW architecture, while using a single input word to predict a target context set of words, is called skip-gram. When the feature vector assigned to a word cannot be used to accurately predict that word’s context, the components of the vector are adjusted. Each word’s context in the corpus is the \"teacher\" sending error signals back to adjust the feature vector. The vectors of words judged similar by their context are nudged closer together by adjusting the numbers in the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2395a5-987a-47ee-bb15-8c70e38f404d",
   "metadata": {},
   "source": [
    "Note that https://arxiv.org/pdf/1411.2738.pdf provides a good breakdown of the architecture, its inputs/outputs and the weight update algorithm. Unlike conventional neural networks, the important point of CBOW is the hidden layer. The hidden layer is an $n$-node layer, which due to the initial one-hot-encoding of the word vector input, serves to create a word embedding in the $n$-dimensional space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdb04af-6018-4125-94d0-0b1e6fbb1845",
   "metadata": {},
   "source": [
    "Below we use the gensim package that trains the word2vec network and extracts the hidden layer, word vector embeddings. Naturally Word2Vec has some choice parameters. \n",
    " - The first is the corpus/text data itself.\n",
    " - The second is `min_count` which removes/ignore words with counts below min_count (due to the fact they are incosequential to meaning, and could even be typos).\n",
    " - `size` defines the length of the embedding vector/number of nodes in the hidden layer.\n",
    " - `workers` is also used for parallelization purposes, important for larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ee667af-6f06-4a4d-9462-61d2a8c5006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=14, vector_size=100, alpha=0.025>\n",
      "['sentence', 'the', 'is', 'this', 'final', 'and', 'more', 'one', 'another', 'yet', 'second', 'word2vec', 'for', 'first']\n",
      "[-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
      " -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
      " -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
      " -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
      "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
      "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
      "  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
      " -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
      "  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
      "  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
      " -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
      " -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
      "  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
      " -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
      "  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
      " -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
      " -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
      " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
      " -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
      "  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
      " -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
      " -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
      " -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
      "  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
      " -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# define training data\n",
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    " ['this', 'is', 'the', 'second', 'sentence'],\n",
    " ['yet', 'another', 'sentence'],\n",
    " ['one', 'more', 'sentence'],\n",
    " ['and', 'the', 'final', 'sentence']]\n",
    "# train model\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "# summarize the loaded model\n",
    "print(model)\n",
    "# summarize vocabulary\n",
    "words = list(model.wv.index_to_key)\n",
    "print(words)\n",
    "#help(model.wv)\n",
    "# access vector for one word\n",
    "print(model.wv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "02de20b2-42ab-4640-88f3-7d186b06ce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 50)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "# define training data\n",
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    " ['this', 'is', 'the', 'second', 'sentence'],\n",
    " ['yet', 'another', 'sentence'],\n",
    " ['one', 'more', 'sentence'],\n",
    " ['and', 'the', 'final', 'sentence']]\n",
    "# train model\n",
    "model = Word2Vec(sentences, min_count=1, vector_size=50) # vector_size (int, optional) – Dimensionality of the word vectors, essentially size of the \n",
    "# hidden layer.\n",
    "# fit a 2D PCA model to the vectors\n",
    "X = model.wv[model.wv.key_to_index]\n",
    "print(X.shape) # Number of unique words/length of vocabulary, vs. the embedding layer size\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "#print(result)\n",
    "# create a scatter plot of the projection\n",
    "pyplot.scatter(result[:, 0], result[:, 1])\n",
    "words = list(model.wv.index_to_key)\n",
    "for i, word in enumerate(words):\n",
    "     pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d72cbb-8838-4361-8675-8fea1afcbd7a",
   "metadata": {},
   "source": [
    "So this plot represents how similar words are given there word embedding vector representation. The PCA determines the number and description of the axis. Notably first and final are reasonable close, as they denote event descriptions. The others aren't as obvious."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d87313-e5a4-4755-8dc0-6d111e5d84e5",
   "metadata": {},
   "source": [
    "Then we can check some cosine distances between the vectors. Implemented manually, but also using the `most_similar` method from wv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "892b5d44-729e-4eaa-a408-aa6722a88606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': 0, 'the': 1, 'is': 2, 'this': 3, 'final': 4, 'and': 5, 'more': 6, 'one': 7, 'another': 8, 'yet': 9, 'second': 10, 'word2vec': 11, 'for': 12, 'first': 13}\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.key_to_index)\n",
    "print(len(model.wv.key_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ed7ce2b-7460-440a-a4d3-e4039fa72bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_dist(vec1, vec2):\n",
    "    vec1_norm = np.linalg.norm(vec1)\n",
    "    vec2_norm = np.linalg.norm(vec2)\n",
    "    dot_prod = np.dot(vec1,vec2)\n",
    "    return dot_prod/(vec1_norm*vec2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "632d3ca0-e27b-4293-957c-bbea63ef8fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sentence', 0.15019883),\n",
       " ('the', -0.01201754),\n",
       " ('is', 0.020485384),\n",
       " ('this', -0.19830054),\n",
       " ('final', 0.15375377),\n",
       " ('and', 0.30655774),\n",
       " ('more', -0.014133254),\n",
       " ('one', 0.118233494),\n",
       " ('another', -0.14298055),\n",
       " ('yet', 0.12584557),\n",
       " ('second', 0.05599532),\n",
       " ('word2vec', 0.19031364),\n",
       " ('for', -0.08253041),\n",
       " ('first', 1.0)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X[13] corresponds to \"first\"\n",
    "[(model.wv.index_to_key[i],cos_dist(X[i],X[13])) for i in range(0,len(model.wv.key_to_index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "60d17997-270a-4d02-9347-2921b270a432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('and', 0.3065577447414398),\n",
       " ('word2vec', 0.19031362235546112),\n",
       " ('final', 0.15375375747680664),\n",
       " ('sentence', 0.150198832154274),\n",
       " ('yet', 0.12584556639194489),\n",
       " ('one', 0.11823350936174393),\n",
       " ('second', 0.055995337665081024),\n",
       " ('is', 0.020485403016209602),\n",
       " ('the', -0.012017532251775265),\n",
       " ('more', -0.014133245684206486),\n",
       " ('for', -0.0825304239988327),\n",
       " ('another', -0.14298053085803986),\n",
       " ('this', -0.1983005255460739)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"first\",topn=len(X[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
